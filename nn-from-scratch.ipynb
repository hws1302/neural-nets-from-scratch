{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural networks from scratch \n",
        " \n",
        "the scope of this project:\n",
        "- nn's are easy without understanding \n",
        "- that understanding is probably very useful \n",
        "- I like linear algebra and calculus \n",
        "\n",
        "what are the main steps: \n",
        "- constructing this architecture (this is something that is intially very very simple) which allows for feeding forwards an input for given weights and biases \n",
        "- producing a cost function that identifies how well the classifier is \n",
        "- producing a gradient of the cost function for all weights and biases using stochastic gradient descent \n",
        "\n",
        "what extra things I want to understand:\n",
        "- what is the deep connection between deep learning/information theory and thermodymamics (read the Yan Lecunn thing) e.g. understand what partition function is mathematically that makes it sutiable for both \n",
        "- what is probabilistic ML \n",
        "- understand nn's as a function approximation machine\n",
        "- \"neurons that wire together fire together\"\n",
        "\n",
        "\n",
        "# Building a very simple network:\n",
        "\n",
        "**need to add in image of neural net here!**\n",
        "\n",
        "In this notebook I will code up the example given in [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0.pdf) Rumelhart et al. (1986). This was one of the first times that backpropagation, the idea that makes machine learning possible, was formally proposed.\n",
        "\n",
        "In the example, which I strongly recommend reading, the network has 6 input neurons, 2 neurons in a hidden layer and 1 output neuron. The network can learn to tell whether the response is symmetric. \n",
        "\n",
        "\n",
        "Although this example is simple it serves as an important lesson in setting up and initialising a network as it is one thing knowing the maths and another thing to get that maths working in the way you would expect. "
      ],
      "metadata": {
        "id": "3MPV4ln5Wsqe"
      },
      "id": "3MPV4ln5Wsqe"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5e423672",
      "metadata": {
        "id": "5e423672"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6, 2, 1 structure requires (6,2) and (2,1) weight matrices w\n",
        "w1 = np.random.uniform(-0.3, 0.3, size = (2,6))\n",
        "w2 = np.random.uniform(-0.3, 0.3, size = (1,2))"
      ],
      "metadata": {
        "id": "C3eEgIZFWr1E"
      },
      "id": "C3eEgIZFWr1E",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to have a way to feed forward given a (6,) input vector \n",
        "input = np.random.uniform(-0.3, 0.3, size = (6,1))"
      ],
      "metadata": {
        "id": "tbx83w2pWrKV"
      },
      "id": "tbx83w2pWrKV",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finally we must remember to add the non-linearity... lets start of with a sigmoid \n",
        "sig = lambda x: 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "J58Q9X6PQQ6D"
      },
      "id": "J58Q9X6PQQ6D",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "089211c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "089211c9",
        "outputId": "0251c66f-6f44-483e-b44c-ffd8177c4a2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.55146603]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# don't be worried by @ it is concise way of doing np.matmult()\n",
        "# remember for matrix multiplication we go backwards!\n",
        "output = sig(w2 @ sig(w1 @ input))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# feedforward will only do a single layer at a time"
      ],
      "metadata": {
        "id": "gqVF9_wDSH7p"
      },
      "id": "gqVF9_wDSH7p",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem, we want the network to detect mirror symmetry of the input vector.\n",
        "\n",
        "We need to create training data such so that a loss function can be defined... only then can the network begin to learn via minimisation of the loss function.\n",
        "\n",
        "If the input is symmetric we want an output of and if it is not symmetric we want an output of "
      ],
      "metadata": {
        "id": "AAJzly3XNkGX"
      },
      "id": "AAJzly3XNkGX"
    },
    {
      "cell_type": "code",
      "source": [
        "w1_trained = np.array([\n",
        "              [14.2, -3.6, 7.2, -7.2, 3.6, -14.2],\n",
        "              [-14.2, 3.6, -7.1, 7.1, -3.6, 14.2]\n",
        "])\n",
        "\n",
        "w2_trained = np.array([-8.8, -8.8])\n",
        "\n",
        "bias1_trained = [-1.1, -1.1]\n",
        "\n",
        "bias2_trained = [6.4]"
      ],
      "metadata": {
        "id": "96IYs_f4MeBy"
      },
      "id": "96IYs_f4MeBy",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sym_input = np.array([1,2,3,3,2,1])\n",
        "\n",
        "sym_output = w2_trained @ sig(w1_trained @ sym_input + bias1_trained) + bias2_trained \n",
        "\n",
        "sig(sym_output) # we get close to zero-ish (surely something is still wrong?)"
      ],
      "metadata": {
        "id": "csrsO3zCPolU",
        "outputId": "556b0281-9941-4c69-e480-ce4d1f1726c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "csrsO3zCPolU",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.88127689])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- What is the concept of 'on' and 'off' \n",
        "- If it just means > 0 then surely the cost function is undefined (i.e. always infitely large as âˆž is always the best solution)"
      ],
      "metadata": {
        "id": "y1iqprRHLXh4"
      },
      "id": "y1iqprRHLXh4"
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "o-8QdTXgAkO3"
      },
      "id": "o-8QdTXgAkO3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "nn-from-scratch.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}