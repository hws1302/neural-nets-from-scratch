# Building neural networks from scratch using NumPy

### Why would you want to do this? 
In June 2022, the vast majority of deep learning in python is done using the TensorFlow (Google) or PyTorch (Facebook) libraries that make producing a neural network (nn) trivial. Although this provides a fantastic framework for making architectures of any complexity it allows you to make a nn without understand any of the processes going on *under the hood*. For this reason, I thought it would be a great idea to learn the mathemtics behhind nn's by writing all the functions from scratch.  

### What are my aims?
- Gain an intuition for what layers in a nn look like graphically
- Build up the motivation for nn's from logistic regression
- Produce some plots on some basic ideas e.g. gradient descent 
- Produce a set of functions that together can acts as a nn
-  

### What have I found

### Extra things 
- Momentum (ADAM)
- Different activation functions

### Useful resources 
- Deepmind x UCL Deep Learning Lectures
